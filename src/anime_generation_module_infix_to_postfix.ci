


#define PUSH_POSTFIX(__token__) {						\
	if (postfix_buffer_itemsize <= postfix_buffer_nb) goto label__error__postfix_buffer_overflow; \
	postfix_buffer[postfix_buffer_nb] = __token__;			\
	postfix_buffer_nb++;						\
      };								\
      /* END OF MACRO */

#define PUSH_OPERATOR(__token_i__,__token_type__) {			\
	if (operator_stack_itemsize <= operator_stack_nb) goto label__error__operator_stack_overflow; \
	operator_stack_id[operator_stack_nb] = __token_i__;		\
	operator_stack_type[operator_stack_nb] = __token_type__;	\
	operator_stack_nb++;						\
      };								\
      /* END OF MACRO */ 


// RL: Cette fonction ne vérifie pas si la syntaxe de l’expression infixe est correcte. 
//     Cette fonction suppose que la syntaxe est correcte. 
//     Une expression telle que
//       1 2 + + 3 
//    sera acceptée et calculée. 
// ---   
// RL: Cette fonction est mono-syntaxique. 
//     (+, x, etc., ont la même syntaxe) 
// 
// RL: Un analyse poly-syntaxiques devrait intégrer un «pattern matching» qui ventilerait ensuite selon la syntaxe reconnue. 
// ---  
// RL: Il faudrait en amont écrire un vérificateur de syntaxe. 
// RL: Un tel vérificateur devrait: 
//      -- L’erreur pouvant être en profondeur, le vérificateur devrait se souvenir de son chemin. 
// 
// RL: En définitive, avec un répartiteur et une mémoire du chemin, un tel vérificater ressemblerait à un analyseur LALR. 
// ---  
// RL: Un tel vérificateur aurait besoin d’une mémoire tampon de la longueur de la plus longue règle de la grammaire. 
//     Par définition, chaque règle serait inférieure à cette taille, et donc serait contenue dans la mémoire tampon. 
//     En particulier, le sous-arbre en bas à gauche serait entièrement compris dans la mémoire tampon. 
//     Il serait donc possible de le construire. 
// RL: Notons que pour la reconnaissance de la syntaxe, il serait possible de s’arrêter en amont si chaque règle soit distincte au bout de 'k' caractères. 


// RL: La logique de cette fonction est aisée — celle-ci réduit dès que elle peut:  
//      -- Elle réduit les constantes. 
//      -- Elle réduit les expressions postfixes. 
//      -- Ensuite, elle ne réduit pas, mais elle met en attente. 
//         Elle attend quoi? De trouver un opérateur dont la priorité soit plus faible (voire égale) que la priorité de l’opérateur précédent, 
//         et alors elle réduit l’opérateur précédent. 
static int_anime_error_t anime__generation__convert_infix_to_postfix(const anime_t * this, const int_lexeme_t lexeme_start_i, const int8_t lexeme_len, int_lexeme_t * postfix_buffer, const int8_t postfix_buffer_itemsize, int8_t * postfix_buffer_nb_r) { 
  LOCAL_ALLOCA__DECLARE(int16_t,INT16_MAX); 
  int_anime_error_t error_id; 
  assert(NULL != postfix_buffer_nb_r); 
  assert(0 <= lexeme_start_i); 
  assert(0 <= lexeme_len); 
  if (0 == lexeme_len) { *postfix_buffer_nb_r = 0; return ANIME__OK; }; 
  if (ANIME__LONGEST_INFIX_EXPRESSION < lexeme_len) return ANIME__ERROR_GENERIC; 
  if (postfix_buffer_itemsize < lexeme_len) return ANIME__ERROR_GENERIC; 
  if (1 == lexeme_len) { postfix_buffer[0] = lexeme_start_i; *postfix_buffer_nb_r = 1; return ANIME__OK; };
  
  // RL: Les opérateurs précédents moins prioritaires restent en attente. 
  int_lexeme_t           operator_stack_id  [ANIME__LONGEST_INFIX_EXPRESSION]; 
  int_anime_token_type_t operator_stack_type[ANIME__LONGEST_INFIX_EXPRESSION]; 
  int8_t                 operator_stack_nb = 0; 
  const int8_t           operator_stack_itemsize = ANIME__LONGEST_INFIX_EXPRESSION; 

  int8_t postfix_buffer_nb = 0; 
  //int8_t infix_buffer_nb = 0; 
  int_lexeme_t lexeme_i;
  goto label__body; 

  int16_t error_sub__line = -1;
 label__error__sub: { 
    DISPLAY_TRACE(this -> stdlog_d, error_id); 
    return error_id; 
  }; 

  label__body: { 
    postfix_buffer_nb = 0; 
    operator_stack_nb = 0; 
    //infix_buffer_nb = 0; 
    lexeme_i = 0;
    
#if 0
#define INFIX_BUFFER_PRINT(infix_buffer,infix_buffer_nb) {		\
    dputs3(STDERR_FILENO, "infix_buffer[", int_string(infix_buffer_nb),"] = {" "\n"); \
    for (int i = 0; i < infix_buffer_nb; i++) {				\
      dputs_array(STDERR_FILENO, "\t" "[", int_string(i), "] = ", int_string(infix_buffer[i]), "\n"); \
    };									\
    dputs(STDERR_FILENO, "};" "\n");					\
  };									\
  /* END OF MACRO */
#endif 

#if 0
    {
      for (int i = 0; i < lexeme_len; i++) { 
	const int_lexeme_t token_i = i + lexeme_start_i; 
	const int_anime_token_type_t token_type = this -> lexeme_stack__type[token_i]; 
	dputs_array(STDERR_FILENO, "\t" "[", int_string(i), "] = ", int_string(lexeme_start_i + i), " - type = ", int_anime_token_type__get_cstr(token_type), "\n"); 
      };
    };
#endif 
    
    for (;;) { 
      //if (infix_buffer_itemsize <= infix_buffer_nb) goto label__eof_reached; 
      if (lexeme_len <= lexeme_i) goto label__eof_reached; 
      const int_lexeme_t token_i = lexeme_i + lexeme_start_i; 
      const int_anime_token_type_t token_type = this -> lexeme_stack__type[token_i]; 
      
      const int8_t constant_value_huh = CONSTANT_VALUE_HUH(token_type); 
      if (constant_value_huh) { PUSH_POSTFIX(token_i); lexeme_i++; continue; }; 
      
      const bool_t infix_binary_operator_huh = BINARY_OPERATOR_HUH(token_type);
      if (infix_binary_operator_huh) goto label__binop; 
      
      const bool_t prefix_unary_operator_huh = UNARY_PREFIX_OPERATOR_HUH(token_type); 
      if (prefix_unary_operator_huh) { PUSH_OPERATOR(token_i,token_type); lexeme_i++; continue; };  
      
      // sous-expression 
      const bool_t openpar_huh = UNARY_OUTFIX_OPERATOR_HUH__OPEN(token_type); 
      if (openpar_huh) { PUSH_OPERATOR(token_i,token_type); lexeme_i++; continue; };  
      
      const bool_t closepar_huh = UNARY_OUTFIX_OPERATOR_HUH__CLOSE(token_type); 
      if (closepar_huh) { goto label__closepar; }; 
      
      { error_sub__line = __LINE__; goto label__error__unexpected_token; }; 

      assert(false); 
      
    label__closepar: {
	// Semblable à un EOF: on réduit jusqu'à retrouver la parenthèse ouvrante. 
#if 0
	if (true) {
	  dputs3(STDERR_FILENO, "token_i: ", int_string(token_i), "\n"); 
	  //dputs3(STDERR_FILENO, "expr_lexemes_nb:    ", int_string(expr_lexemes_nb), "\n"); 
	  //assert(false); 
	};
#endif 
	for (;;) { 
	  if (0 == operator_stack_nb) { error_sub__line = __LINE__; goto label__error__missing_openpar; }; 
	  operator_stack_nb--; 
	  const int_lexeme_t ope_i = operator_stack_id[operator_stack_nb]; 
	  const int_anime_token_type_t ope_type = this -> lexeme_stack__type[ope_i]; 
	  const bool_t openpar_huh = UNARY_OUTFIX_OPERATOR_HUH__OPEN(ope_type); 
	  if (openpar_huh) break;
	  PUSH_POSTFIX(ope_i);
	  continue; 
	};
	lexeme_i++; 
	continue;
      };
      
    label__binop: {
	// RL: Y a-t-il un opérateur précédent? 
	if (0 == operator_stack_nb) { PUSH_OPERATOR(token_i,token_type); lexeme_i++; continue; }; 
	const int_anime_token_type_t top_type = operator_stack_type[operator_stack_nb-1]; 
	if (top_type >= token_type) { operator_stack_nb--; PUSH_POSTFIX(operator_stack_id[operator_stack_nb]); continue; };
	assert(top_type < token_type); { PUSH_OPERATOR(token_i,token_type); lexeme_i++; continue; }; 
      };
      
    label__error__missing_openpar: { 
	error_id = ANIME__DATA_GENERATION__MISSING_OPENPAR; 
	goto label__error__sub; 
      }; 
      
      label__error__unexpected_token: {
	error_id = ANIME__DATA_GENERATION__UNEXPECTED_TOKEN; 
	goto label__error__sub; 
      }; 
      
    }; 
    /* NOT REACHED */ assert(false); 
  };

 label__eof_reached: { 
    for (;;) { 
      if (0 == operator_stack_nb) break; 
      operator_stack_nb--; 
      PUSH_POSTFIX(operator_stack_id[operator_stack_nb]); 
    };
    *postfix_buffer_nb_r = postfix_buffer_nb; 
    return ANIME__OK; 
  }; 

 label__error__postfix_buffer_overflow: {
    return ANIME__ERROR_GENERIC; 
  };

 label__error__operator_stack_overflow: {
    return ANIME__ERROR_GENERIC; 
  };

 label__error__not_an_operator: { 
    error_id = ANIME__ERROR_GENERIC; 
    const char error_msg[] = "NOT AN OPERATOR";
    enum { ERROR_STR_BYTESIZE = 2048 }; 
    char error_str_loc[ERROR_STR_BYTESIZE]; 
    snprintf(error_str_loc, ERROR_STR_BYTESIZE, "<%s>: " "%s[%d]: " "%s: %s", anime__filename_get(this), error_id > 0 ? LANG("Attention","Warning") : LANG("Erreur","Error"), error_id, int_anime_error__get_cstr(error_id), anime__error_cstr_get(this)); 
    if (this -> stdlog_d > 0) {  dputs_array(this -> stdlog_d, "{", __FILE__, ":", STRINGIFY(__LINE__), ":<", __func__, "()>}: ", error_str_loc, ": ", error_msg, "\n"); }; 
    return error_id; 
  };
  
  assert(false);
};




